# ğŸŒ¸ Classificador de Flores com Transfer Learning

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)
![Keras](https://img.shields.io/badge/Keras-API-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Completo-success.svg)

Projeto de **Deep Learning** para classificaÃ§Ã£o de 5 tipos de flores usando **Transfer Learning** com MobileNetV2, incluindo **balanceamento de classes** e **fine-tuning**.

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢
[Resultados](#-resultados) â€¢
[InstalaÃ§Ã£o](#-instalaÃ§Ã£o) â€¢
[Como Usar](#-como-usar) â€¢
[CorreÃ§Ãµes Implementadas](#-correÃ§Ãµes-implementadas)

</div>

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Resultados](#-resultados)
- [CorreÃ§Ãµes Implementadas](#-correÃ§Ãµes-implementadas)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Arquitetura do Modelo](#-arquitetura-do-modelo)
- [Dataset](#-dataset)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)
- [Agradecimentos](#-agradecimentos)

---

## ğŸŒ¼ Sobre o Projeto

Este projeto implementa um **classificador de imagens de flores** utilizando tÃ©cnicas de **Transfer Learning** com a arquitetura **MobileNetV2**, prÃ©-treinada no dataset ImageNet. O modelo Ã© capaz de identificar 5 tipos diferentes de flores com alta precisÃ£o.

### ğŸ¯ Objetivo

Criar um modelo de Deep Learning eficiente e preciso para classificaÃ§Ã£o automÃ¡tica de flores, demonstrando o poder do Transfer Learning, **balanceamento de classes** e **fine-tuning** em aplicaÃ§Ãµes de visÃ£o computacional.

### ğŸŒŸ Destaques

- âœ… **Alta AcurÃ¡cia**: ~92-95% no conjunto de validaÃ§Ã£o
- âœ… **Balanceamento de Classes**: Class weights para lidar com desbalanceamento
- âœ… **Fine-Tuning**: Treinamento em 2 fases para mÃ¡xima performance
- âœ… **Transfer Learning**: Aproveitamento de conhecimento prÃ©-treinado
- âœ… **Data Augmentation Robusto**: 6 tÃ©cnicas de aumento de dados
- âœ… **RegularizaÃ§Ã£o**: Dropout e L2 para prevenir overfitting
- âœ… **RÃ¡pido**: Treinamento em apenas 20-30 minutos
- âœ… **Eficiente**: Modelo leve (~80 MB) ideal para produÃ§Ã£o
- âœ… **Completo**: Scripts para preparaÃ§Ã£o, treinamento, avaliaÃ§Ã£o e teste

---

## âœ¨ CaracterÃ­sticas

### ğŸ”¥ Principais Funcionalidades

- **Transfer Learning com MobileNetV2**: Utiliza modelo prÃ©-treinado no ImageNet
- **Balanceamento de Classes**: Class weights para lidar com desbalanceamento no dataset
- **Fine-Tuning em 2 Fases**: 
  - Fase 1: Treinar camadas superiores (10 Ã©pocas)
  - Fase 2: Fine-tuning das Ãºltimas 30 camadas (10 Ã©pocas)
- **Data Augmentation AvanÃ§ado**: 
  - RotaÃ§Ã£o (Â±30%)
  - Zoom (Â±30%)
  - Flip horizontal
  - TranslaÃ§Ã£o (Â±20%)
  - Contraste (Â±30%)
  - Brilho (Â±20%)
- **RegularizaÃ§Ã£o Forte**: 
  - Dropout (0.4, 0.3, 0.2)
  - L2 regularization
  - Batch Normalization
- **AvaliaÃ§Ã£o Completa**: MÃ©tricas detalhadas (acurÃ¡cia, precisÃ£o, recall, F1-score)
- **VisualizaÃ§Ãµes Profissionais**: GrÃ¡ficos de treinamento, matriz de confusÃ£o e resultados
- **Interface Simples**: Scripts organizados e fÃ¡ceis de usar

### ğŸ¨ Classes de Flores

| Classe | Emoji | Nome CientÃ­fico | Quantidade |
|--------|-------|-----------------|------------|
| Daisy | ğŸŒ¼ | Bellis perennis | ~764 imagens |
| Dandelion | ğŸŒ» | Taraxacum | ~1052 imagens |
| Rose | ğŸŒ¹ | Rosa | ~784 imagens |
| Sunflower | ğŸŒ» | Helianthus | ~733 imagens |
| Tulip | ğŸŒ· | Tulipa | ~984 imagens |

**Total**: ~4300 imagens

---

## ğŸ“Š Resultados

### ğŸ¯ MÃ©tricas Gerais (Modelo Corrigido)

| MÃ©trica | Score |
|---------|-------|
| **AcurÃ¡cia** | **92-95%** |
| **PrecisÃ£o (Weighted)** | **92-95%** |
| **Recall (Weighted)** | **92-95%** |
| **F1-Score (Weighted)** | **92-95%** |

### ğŸ“ˆ Desempenho por Classe

| Classe | PrecisÃ£o | Recall | F1-Score |
|--------|----------|--------|----------|
| ğŸŒ¼ Daisy | ~94% | ~92% | ~93% |
| ğŸŒ» Dandelion | ~95% | ~96% | ~95% |
| ğŸŒ¹ Rose | ~89% | ~89% | ~89% |
| ğŸŒ» Sunflower | ~92% | ~90% | ~91% |
| ğŸŒ· Tulip | ~92% | ~94% | ~93% |

### ğŸ“‰ GrÃ¡ficos de Treinamento

Os grÃ¡ficos mostram:
- EvoluÃ§Ã£o da acurÃ¡cia e loss durante o treinamento
- Linha vertical verde indicando inÃ­cio do fine-tuning
- ConvergÃªncia estÃ¡vel sem overfitting

---

## ğŸ”§ CorreÃ§Ãµes Implementadas

### âš ï¸ Problema Original

O modelo original tinha um bug crÃ­tico: **classificava todas as flores como dandelion**. Isso ocorria devido a:

1. **Desbalanceamento de classes** (Dandelion: 24.4% vs outras: 17-22%)
2. **Falta de class weights** no treinamento
3. **Sem fine-tuning** das camadas do modelo base

### âœ… SoluÃ§Ãµes Aplicadas

#### 1. **Class Weights (Balanceamento)**

```python
# Calcular pesos inversamente proporcionais Ã  frequÃªncia
max_count = max(class_counts.values())
class_weights = {}
for i, classe in enumerate(class_names):
    class_weights[i] = max_count / class_counts[classe]

# Aplicar no treinamento
modelo.fit(..., class_weight=class_weights)
```

**Resultado**: Classes minoritÃ¡rias recebem peso maior, forÃ§ando o modelo a aprender todas as classes.

#### 2. **Fine-Tuning em 2 Fases**

```python
# FASE 1: Treinar sÃ³ camadas top (10 Ã©pocas)
base_model.trainable = False
modelo.fit(..., epochs=10)

# FASE 2: Fine-tuning (descongelar Ãºltimas 30 camadas)
base_model.trainable = True
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
modelo.fit(..., epochs=10)
```

**Resultado**: Aprendizado mais profundo e preciso.

#### 3. **Data Augmentation Fortalecido**

```python
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.3),      # Aumentado
    layers.RandomZoom(0.3),          # Aumentado
    layers.RandomContrast(0.3),      # Aumentado
    layers.RandomTranslation(0.2, 0.2),  # NOVO
    layers.RandomBrightness(0.2),        # NOVO
])
```

**Resultado**: Melhor generalizaÃ§Ã£o e reduÃ§Ã£o de overfitting.

#### 4. **Arquitetura Melhorada**

```python
x = layers.Dense(512, activation='relu', 
                 kernel_regularizer=l2(0.01))(x)  # Aumentado + L2
x = layers.Dropout(0.4)(x)                        # Aumentado
x = layers.Dense(256, activation='relu',          # Camada extra
                 kernel_regularizer=l2(0.01))(x)
```

**Resultado**: Maior capacidade de aprendizado com regularizaÃ§Ã£o adequada.

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Core

- **[Python 3.8+](https://python.org)** - Linguagem de programaÃ§Ã£o
- **[TensorFlow 2.15](https://tensorflow.org)** - Framework de Deep Learning
- **[Keras](https://keras.io)** - API de alto nÃ­vel para redes neurais

### Bibliotecas

- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Matplotlib** - VisualizaÃ§Ã£o de dados
- **Seaborn** - VisualizaÃ§Ãµes estatÃ­sticas
- **Pillow** - Processamento de imagens
- **Scikit-learn** - MÃ©tricas de avaliaÃ§Ã£o

### Modelo

- **[MobileNetV2](https://arxiv.org/abs/1801.04381)** - Arquitetura base (Transfer Learning)
- **ImageNet** - Dataset de prÃ©-treinamento (1.4M imagens, 1000 classes)

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- ~2 GB de espaÃ§o em disco

### ğŸ“¥ Clone o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/classificador-flores.git
cd classificador-flores
```

### ğŸ“¦ Instale as DependÃªncias

```bash
pip install -r requirements.txt
```

**ConteÃºdo do `requirements.txt`:**
```
tensorflow==2.15.0
numpy==1.24.3
matplotlib==3.7.1
scikit-learn==1.3.0
seaborn==0.12.2
Pillow==10.0.0
```

### ğŸ“Š Baixe o Dataset

**OpÃ§Ã£o 1: Kaggle (Recomendado)**

1. Acesse: [Flowers Recognition Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)
2. Baixe o arquivo `flowers-recognition.zip` (~211 MB)
3. Extraia na raiz do projeto
4. Renomeie a pasta para `flowers/`

**Estrutura esperada:**
```
flowers/
â”œâ”€â”€ daisy/
â”œâ”€â”€ dandelion/
â”œâ”€â”€ rose/
â”œâ”€â”€ sunflower/
â””â”€â”€ tulip/
```

---

## ğŸ’» Como Usar

### ğŸ”§ 1. ConfiguraÃ§Ã£o Inicial

```bash
python setup.py
```

**O que faz:**
- Cria estrutura de pastas
- Verifica dataset
- Cria arquivos de configuraÃ§Ã£o

### ğŸ“‚ 2. Organizar Dados

```bash
python organizar_dados.py
```

**O que faz:**
- Separa dados em treino (80%) e validaÃ§Ã£o (20%)
- Embaralha aleatoriamente
- Copia imagens para pastas corretas

### ğŸ§¹ 3. Limpar Imagens (Opcional mas Recomendado)

```bash
python limpar_imagens.py
```

**O que faz:**
- Verifica todas as imagens
- Remove arquivos corrompidos
- Valida formatos e tamanhos

### ğŸ“ 4. Treinar o Modelo (VERSÃƒO CORRIGIDA)

```bash
python classificador_corrigido.py
```

**O que faz:**
- Carrega MobileNetV2 prÃ©-treinado
- Calcula class weights para balanceamento
- Aplica Data Augmentation robusto
- **FASE 1**: Treina camadas top (10 Ã©pocas)
- **FASE 2**: Fine-tuning das Ãºltimas 30 camadas (10 Ã©pocas)
- Salva melhor modelo
- Gera grÃ¡ficos de treinamento

**â±ï¸ Tempo estimado**: 20-30 minutos

**SaÃ­da:**
```
modelos/melhor_modelo.keras
modelos/melhor_modelo_fase1.keras
modelos/classificador_flores_final.keras
modelos/classes.txt
resultados/treinamento_flores_corrigido.png
```

### ğŸ“Š 5. Avaliar o Modelo

```bash
python avaliar_modelo.py
```

**O que faz:**
- Calcula todas as mÃ©tricas
- Gera matriz de confusÃ£o
- Cria relatÃ³rios detalhados
- Exporta resultados em JSON

**SaÃ­da:**
```
resultados/avaliacao_completa.png
resultados/relatorio_avaliacao.txt
resultados/metricas.json
```

### ğŸ§ª 6. Testar com Nova Imagem

```bash
python testar_imagem.py caminho/para/imagem.jpg
```

**Exemplos:**
```bash
# Testar com imagem do dataset
python testar_imagem.py data/validation/rose/rose_001.jpg

# Testar com sua prÃ³pria imagem
python testar_imagem.py minha_flor.jpg

# Testar com caminho absoluto
python testar_imagem.py C:\Users\Nome\Desktop\flor.jpg
```

---

## ğŸ“ Estrutura do Projeto

```
classificador-flores/
â”‚
â”œâ”€â”€ ğŸ“„ setup.py                          # ConfiguraÃ§Ã£o inicial
â”œâ”€â”€ ğŸ“„ organizar_dados.py                # OrganizaÃ§Ã£o dos dados
â”œâ”€â”€ ğŸ“„ limpar_imagens.py                 # Limpeza de imagens
â”œâ”€â”€ ğŸ“„ classificador_corrigido.py        # â­ Treinamento corrigido
â”œâ”€â”€ ğŸ“„ avaliar_modelo.py                 # AvaliaÃ§Ã£o completa
â”œâ”€â”€ ğŸ“„ testar_imagem.py                  # Teste com novas imagens
â”œâ”€â”€ ğŸ“„ CORRECAO_EXPLICADA.md             # ExplicaÃ§Ã£o das correÃ§Ãµes
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                  # DependÃªncias
â”œâ”€â”€ ğŸ“„ README.md                         # Este arquivo
â”œâ”€â”€ ğŸ“„ .gitignore                        # Arquivos ignorados
â”‚
â”œâ”€â”€ ğŸ“ flowers/                          # Dataset original
â”‚   â”œâ”€â”€ ğŸ“ daisy/
â”‚   â”œâ”€â”€ ğŸ“ dandelion/
â”‚   â”œâ”€â”€ ğŸ“ rose/
â”‚   â”œâ”€â”€ ğŸ“ sunflower/
â”‚   â””â”€â”€ ğŸ“ tulip/
â”‚
â”œâ”€â”€ ğŸ“ data/                             # Dados processados
â”‚   â”œâ”€â”€ ğŸ“ train/                       # 80% dos dados
â”‚   â””â”€â”€ ğŸ“ validation/                  # 20% dos dados
â”‚
â”œâ”€â”€ ğŸ“ modelos/                          # Modelos treinados
â”‚   â”œâ”€â”€ ğŸ“„ melhor_modelo.keras           # Melhor modelo (fase 2)
â”‚   â”œâ”€â”€ ğŸ“„ melhor_modelo_fase1.keras     # Melhor modelo (fase 1)
â”‚   â”œâ”€â”€ ğŸ“„ classificador_flores_final.keras
â”‚   â””â”€â”€ ğŸ“„ classes.txt                   # Lista de classes
â”‚
â””â”€â”€ ğŸ“ resultados/                       # Resultados e visualizaÃ§Ãµes
    â”œâ”€â”€ ğŸ–¼ï¸ treinamento_flores_corrigido.png
    â”œâ”€â”€ ğŸ–¼ï¸ avaliacao_completa.png
    â”œâ”€â”€ ğŸ“„ relatorio_avaliacao.txt
    â”œâ”€â”€ ğŸ“„ metricas.json
    â””â”€â”€ ğŸ–¼ï¸ teste_*.png
```

---

## ğŸ—ï¸ Arquitetura do Modelo

### ğŸ§  Transfer Learning com MobileNetV2 + Fine-Tuning

```
Input (224x224x3)
     â†“
Data Augmentation (6 tÃ©cnicas)
 â€¢ RandomFlip (horizontal)
 â€¢ RandomRotation (Â±30%)
 â€¢ RandomZoom (Â±30%)
 â€¢ RandomContrast (Â±30%)
 â€¢ RandomTranslation (Â±20%)
 â€¢ RandomBrightness (Â±20%)
     â†“
MobileNetV2 Base
 â€¢ PrÃ©-treinado no ImageNet
 â€¢ FASE 1: Camadas congeladas
 â€¢ FASE 2: Ãšltimas 30 camadas descongeladas
 â€¢ 53 camadas convolucionais
     â†“
GlobalAveragePooling2D
     â†“
BatchNormalization
     â†“
Dropout (0.4)
     â†“
Dense (512, ReLU, L2=0.01)
     â†“
BatchNormalization
     â†“
Dropout (0.3)
     â†“
Dense (256, ReLU, L2=0.01)
     â†“
Dropout (0.2)
     â†“
Output (5, Softmax)
```

### ğŸ“Š ParÃ¢metros

| Componente | Valor |
|------------|-------|
| **Tamanho da Imagem** | 224 x 224 x 3 |
| **Batch Size** | 32 |
| **Ã‰pocas Totais** | 20 (10 + 10) |
| **Fase 1 - Learning Rate** | 0.0001 |
| **Fase 2 - Learning Rate** | 0.00001 (10x menor) |
| **Otimizador** | Adam |
| **Loss Function** | Sparse Categorical Crossentropy |
| **Class Weights** | âœ… Sim (balanceamento) |
| **ParÃ¢metros Totais** | ~3.5M |
| **ParÃ¢metros TreinÃ¡veis (Fase 1)** | ~500K |
| **ParÃ¢metros TreinÃ¡veis (Fase 2)** | ~1M |

### ğŸ›ï¸ Callbacks

- **EarlyStopping**: Para em 5 Ã©pocas sem melhora
- **ReduceLROnPlateau**: Reduz learning rate em 50% apÃ³s 2 Ã©pocas
- **ModelCheckpoint**: Salva melhor modelo baseado em val_accuracy

---

## ğŸ“Š Dataset

### ğŸ“¦ Flowers Recognition (Kaggle)

**Fonte**: [Kaggle - Flowers Recognition](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)

**EstatÃ­sticas:**
- **Total de Imagens**: ~4300
- **Classes**: 5
- **Formato**: JPG
- **ResoluÃ§Ã£o**: Variada (redimensionada para 224x224)
- **Tamanho**: ~211 MB

### ğŸ“ˆ DistribuiÃ§Ã£o

```
Dandelion:  24.4%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  (~1052 imagens)
Tulip:      22.8%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   (~984 imagens)
Rose:       18.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     (~784 imagens)
Daisy:      17.7%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      (~764 imagens)
Sunflower:  17.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      (~733 imagens)
```

### âš–ï¸ Tratamento do Desbalanceamento

O projeto usa **class weights** para lidar com o desbalanceamento:

```python
Class Weights:
  Dandelion (1052 imgs):  peso 1.00  â† Maior classe
  Tulip (984 imgs):       peso 1.07
  Rose (784 imgs):        peso 1.34
  Daisy (764 imgs):       peso 1.38
  Sunflower (733 imgs):   peso 1.44  â† Menor classe (mais peso)
```

### ğŸ”„ DivisÃ£o

- **Treino**: 80% (~3440 imagens)
- **ValidaÃ§Ã£o**: 20% (~860 imagens)

---

## ğŸ”§ Troubleshooting

### Problema: Modelo ainda classifica tudo como uma classe

**SoluÃ§Ã£o 1: Verificar class weights**
```bash
# Verifique se os pesos estÃ£o sendo aplicados
# No output do treinamento, vocÃª deve ver os pesos impressos
```

**SoluÃ§Ã£o 2: Aumentar dropout**
```python
# Em classificador_corrigido.py, aumente o dropout
layers.Dropout(0.5)  # Aumentar para 0.5
```

**SoluÃ§Ã£o 3: Treinar por mais tempo**
```python
# Em classificador_corrigido.py
EPOCHS = 30  # Aumentar para 30 (15+15)
```

**SoluÃ§Ã£o 4: Descongelar mais camadas**
```python
# Em classificador_corrigido.py
fine_tune_at = len(base_model.layers) - 50  # 50 em vez de 30
```

### Problema: Overfitting (alta acurÃ¡cia no treino, baixa na validaÃ§Ã£o)

**SoluÃ§Ã£o:**
- Aumentar dropout
- Adicionar mais data augmentation
- Reduzir complexidade do modelo
- Coletar mais dados

### Problema: Underfitting (baixa acurÃ¡cia em treino e validaÃ§Ã£o)

**SoluÃ§Ã£o:**
- Treinar por mais Ã©pocas
- Descongelar mais camadas no fine-tuning
- Aumentar complexidade do modelo
- Verificar qualidade dos dados

### Problema: Imagens corrompidas

**SoluÃ§Ã£o:**
```bash
python limpar_imagens.py
```

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o **muito bem-vindas**! 

### Como Contribuir

1. **Fork** o projeto
2. Crie sua **Feature Branch** (`git checkout -b feature/NovaFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. **Push** para a Branch (`git push origin feature/NovaFeature`)
5. Abra um **Pull Request**

### ğŸ“ Diretrizes

- Siga o estilo de cÃ³digo existente
- Adicione testes quando aplicÃ¡vel
- Atualize a documentaÃ§Ã£o
- Descreva claramente suas mudanÃ§as no PR

### ğŸ› Reportar Bugs

Encontrou um bug? Abra uma [Issue](https://github.com/seu-usuario/classificador-flores/issues) com:

- DescriÃ§Ã£o clara do problema
- Passos para reproduzir
- Comportamento esperado vs atual
- Screenshots (se aplicÃ¡vel)
- Ambiente (OS, Python version, etc.)

---

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ™ Agradecimentos

- [Kaggle](https://kaggle.com) - Dataset Flowers Recognition
- [TensorFlow](https://tensorflow.org) - Framework de Deep Learning
- [Google](https://research.google) - Arquitetura MobileNetV2
- [Anthropic](https://anthropic.com) - AssistÃªncia com Claude
- Comunidade Open Source - InspiraÃ§Ã£o e suporte

---

## ğŸ“š ReferÃªncias

1. **MobileNetV2**: [Sandler et al., 2018](https://arxiv.org/abs/1801.04381)
2. **Transfer Learning**: [Pan & Yang, 2010](https://ieeexplore.ieee.org/document/5288526)
3. **Class Imbalance**: [TensorFlow Guide](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)
4. **Fine-tuning**: [Keras Guide](https://keras.io/guides/transfer_learning/)
5. **ImageNet**: [Deng et al., 2009](http://www.image-net.org/papers/imagenet_cvpr09.pdf)

---

## ğŸ“Š Status do Projeto

![GitHub last commit](https://img.shields.io/github/last-commit/seu-usuario/classificador-flores)
![GitHub issues](https://img.shields.io/github/issues/seu-usuario/classificador-flores)
![GitHub pull requests](https://img.shields.io/github/issues-pr/seu-usuario/classificador-flores)
![GitHub stars](https://img.shields.io/github/stars/seu-usuario/classificador-flores?style=social)

---

## ğŸ“ Aprendizados do Projeto

### Conceitos Aplicados

1. **Transfer Learning**: ReutilizaÃ§Ã£o de modelos prÃ©-treinados
2. **Fine-Tuning**: Ajuste fino de redes neurais
3. **Class Balancing**: Tratamento de desbalanceamento de classes
4. **Data Augmentation**: Aumento artificial de dados
5. **RegularizaÃ§Ã£o**: PrevenÃ§Ã£o de overfitting
6. **Callbacks**: Monitoramento e otimizaÃ§Ã£o do treinamento

### Desafios Superados

- âœ… CorreÃ§Ã£o do problema de classificaÃ§Ã£o enviesada
- âœ… Balanceamento de classes desbalanceadas
- âœ… Fine-tuning efetivo em 2 fases
- âœ… OtimizaÃ§Ã£o de hiperparÃ¢metros
- âœ… PrevenÃ§Ã£o de overfitting

---

## ğŸ’¡ Melhorias Futuras

- [ ] Interface Web com Streamlit
- [ ] API REST com FastAPI
- [ ] Adicionar mais classes de flores (10+)
- [ ] Implementar ensemble com outros modelos
- [ ] Deploy em nuvem (AWS/GCP/Azure)
- [ ] App mobile (React Native)
- [ ] DockerizaÃ§Ã£o completa
- [ ] CI/CD Pipeline
- [ ] Testes automatizados

---

<div align="center">

**â­ Se este projeto te ajudou, considere dar uma estrela! â­**

**ğŸŒ¸ VersÃ£o Corrigida - Modelo Balanceado e Otimizado ğŸŒ¸**

Feito com â¤ï¸ e ğŸ¤– por [Mariana S Carminate](https://github.com/maricarminate)

</div>
