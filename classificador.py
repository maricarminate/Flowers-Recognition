print("ğŸŒ¸ CLASSIFICADOR DE FLORES - TRANSFER LEARNING")
print("=" * 70)

# Imports
print("\n[1/6] Importando bibliotecas...")
import sys
import os

# FIX: Resolver problema de encoding no Windows
if sys.platform == 'win32':
    import locale
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
    
# FIX: ForÃ§ar UTF-8 no Python
os.environ['PYTHONIOENCODING'] = 'utf-8'

# Continua o resto do cÃ³digo normalmente...

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import MobileNetV2
import matplotlib.pyplot as plt
import numpy as np

print("âœ… Bibliotecas importadas!")

# ConfiguraÃ§Ãµes
IMG_SIZE = 224  # MobileNetV2 usa 224x224
BATCH_SIZE = 32
EPOCHS = 15
LEARNING_RATE = 0.0001

DIRETORIO_TREINO = 'data/train'
DIRETORIO_VALIDACAO = 'data/validation'

print("\n[2/6] Preparando dados...")
print(f"   Tamanho das imagens: {IMG_SIZE}x{IMG_SIZE}")
print(f"   Batch size: {BATCH_SIZE}")
print(f"   Ã‰pocas: {EPOCHS}")

# Criar datasets usando a API do TensorFlow
train_ds = keras.preprocessing.image_dataset_from_directory(
    DIRETORIO_TREINO,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    seed=123
)

val_ds = keras.preprocessing.image_dataset_from_directory(
    DIRETORIO_VALIDACAO,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    seed=123
)

# Obter nomes das classes
class_names = train_ds.class_names
num_classes = len(class_names)

print(f"âœ… Dados carregados!")
print(f"   Classes: {class_names}")
print(f"   NÃºmero de classes: {num_classes}")

# OtimizaÃ§Ã£o de performance
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# Data Augmentation
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.2),
])

# Preprocessing para MobileNetV2
preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

print("\n[3/6] Criando modelo com Transfer Learning...")

# Carregar MobileNetV2 prÃ©-treinado
base_model = MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)

# Congelar camadas do modelo base
base_model.trainable = False

print(f"   Base: MobileNetV2")
print(f"   Camadas congeladas: {len(base_model.layers)}")

# Construir modelo completo
inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = data_augmentation(inputs)
x = preprocess_input(x)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(num_classes, activation='softmax')(x)

modelo = keras.Model(inputs, outputs)

print("âœ… Modelo criado!")

# Compilar
modelo.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print("\nğŸ“Š Resumo do modelo:")
modelo.summary()

# Callbacks
print("\n[4/6] Configurando callbacks...")

callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=4,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=2,
        min_lr=1e-7,
        verbose=1
    ),
    keras.callbacks.ModelCheckpoint(
        'modelos/melhor_modelo.keras',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

print("âœ… Callbacks configurados!")

# Treinar
print("\n[5/6] INICIANDO TREINAMENTO...")
print("=" * 70)
print("â° Tempo estimado: 15-20 minutos")
print("ğŸ’¡ Acompanhe o progresso abaixo:")
print("=" * 70 + "\n")

historico = modelo.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

print("\n" + "=" * 70)
print("âœ… TREINAMENTO CONCLUÃDO!")
print("=" * 70)

# Salvar modelo final
print("\n[6/6] Salvando modelo e resultados...")

modelo.save('modelos/classificador_flores_final.keras')
print("âœ… Modelo salvo: modelos/classificador_flores_final.keras")

# Salvar classes
with open('modelos/classes.txt', 'w', encoding='utf-8') as f:
    for classe in class_names:
        f.write(f"{classe}\n")
print("âœ… Classes salvas: modelos/classes.txt")

# Gerar grÃ¡ficos
print("\nğŸ“Š Gerando grÃ¡ficos...")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# AcurÃ¡cia
epochs_range = range(1, len(historico.history['accuracy']) + 1)
ax1.plot(epochs_range, historico.history['accuracy'], 
         'b-o', label='Treino', linewidth=2.5, markersize=8)
ax1.plot(epochs_range, historico.history['val_accuracy'], 
         'r-o', label='ValidaÃ§Ã£o', linewidth=2.5, markersize=8)
ax1.set_title('ğŸ¯ AcurÃ¡cia do Modelo', fontsize=18, fontweight='bold', pad=20)
ax1.set_xlabel('Ã‰poca', fontsize=14)
ax1.set_ylabel('AcurÃ¡cia', fontsize=14)
ax1.legend(fontsize=13, loc='lower right')
ax1.grid(True, alpha=0.3, linestyle='--')
ax1.set_ylim([0, 1])

# Loss
ax2.plot(epochs_range, historico.history['loss'], 
         'b-o', label='Treino', linewidth=2.5, markersize=8)
ax2.plot(epochs_range, historico.history['val_loss'], 
         'r-o', label='ValidaÃ§Ã£o', linewidth=2.5, markersize=8)
ax2.set_title('ğŸ“‰ Loss do Modelo', fontsize=18, fontweight='bold', pad=20)
ax2.set_xlabel('Ã‰poca', fontsize=14)
ax2.set_ylabel('Loss', fontsize=14)
ax2.legend(fontsize=13, loc='upper right')
ax2.grid(True, alpha=0.3, linestyle='--')

plt.tight_layout()
plt.savefig('resultados/treinamento_flores.png', dpi=300, bbox_inches='tight')
print("âœ… GrÃ¡ficos salvos: resultados/treinamento_flores.png")

# Resultado final
print("\n" + "=" * 70)
print("ğŸ‰ PROJETO CONCLUÃDO COM SUCESSO!")
print("=" * 70)

acuracia_final = historico.history['val_accuracy'][-1]
loss_final = historico.history['val_loss'][-1]
melhor_acuracia = max(historico.history['val_accuracy'])

print(f"\nğŸ“Š RESULTADOS FINAIS:")
print(f"   ğŸ¯ AcurÃ¡cia Final: {acuracia_final:.4f} ({acuracia_final*100:.2f}%)")
print(f"   ğŸŒŸ Melhor AcurÃ¡cia: {melhor_acuracia:.4f} ({melhor_acuracia*100:.2f}%)")
print(f"   ğŸ“‰ Loss Final: {loss_final:.4f}")

if acuracia_final > 0.95:
    print("   ğŸŒŸ EXCELENTE! Transfer Learning funcionou perfeitamente!")
elif acuracia_final > 0.90:
    print("   ğŸ‘ MUITO BOM! Resultado acima do esperado!")
elif acuracia_final > 0.85:
    print("   âœ… BOM! Resultado satisfatÃ³rio!")
else:
    print("   âš ï¸  RazoÃ¡vel. Considere treinar por mais Ã©pocas.")

print(f"\nğŸ“ ARQUIVOS GERADOS:")
print(f"   âœ… modelos/classificador_flores_final.keras")
print(f"   âœ… modelos/melhor_modelo.keras")
print(f"   âœ… modelos/classes.txt")
print(f"   âœ… resultados/treinamento_flores.png")

print(f"\nğŸ“Š CLASSES TREINADAS:")
emoji_map = {
    'daisy': 'ğŸŒ¼',
    'dandelion': 'ğŸŒ»',
    'rose': 'ğŸŒ¹',
    'sunflower': 'ğŸŒ»',
    'tulip': 'ğŸŒ·'
}
for i, classe in enumerate(class_names, 1):
    emoji = emoji_map.get(classe, 'ğŸŒ¸')
    print(f"   {i}. {emoji} {classe.capitalize()}")

print(f"\nğŸ“ PRÃ“XIMO PASSO:")
print(f"   python 5_testar_imagem.py caminho/para/imagem.jpg")

print("\n" + "=" * 70)
print("ğŸŒ¸ Obrigado por usar o Classificador de Flores! ğŸŒ¸")
print("=" * 70)